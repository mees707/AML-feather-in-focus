{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a20399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\meesa\\anaconda3\\envs\\feather-in-focus\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58164ab",
   "metadata": {},
   "source": [
    "# model trainen zonder attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211a1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label\n",
       "0        /train_images/1.jpg      1\n",
       "1        /train_images/2.jpg      1\n",
       "2        /train_images/3.jpg      1\n",
       "3        /train_images/4.jpg      1\n",
       "4        /train_images/5.jpg      1\n",
       "...                      ...    ...\n",
       "3921  /train_images/3922.jpg    200\n",
       "3922  /train_images/3923.jpg    200\n",
       "3923  /train_images/3924.jpg    200\n",
       "3924  /train_images/3925.jpg    200\n",
       "3925  /train_images/3926.jpg    200\n",
       "\n",
       "[3926 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"feather-in-focus/class_names.npy\", allow_pickle=True).item()\n",
    "df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db273c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = np.load(\"feather-in-focus/attributes.npy\")\n",
    "len(attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35500a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      1   \n",
       "1        /train_images/2.jpg      1   \n",
       "2        /train_images/3.jpg      1   \n",
       "3        /train_images/4.jpg      1   \n",
       "4        /train_images/5.jpg      1   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    200   \n",
       "3922  /train_images/3923.jpg    200   \n",
       "3923  /train_images/3924.jpg    200   \n",
       "3924  /train_images/3925.jpg    200   \n",
       "3925  /train_images/3926.jpg    200   \n",
       "\n",
       "                                             attributes  \n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "...                                                 ...  \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "\n",
       "[3926 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_list = []\n",
    "for i in range(len(df)):\n",
    "    att_list.append(attributes[df['label'][i]-1])  \n",
    "    \n",
    "df['attributes'] = att_list\n",
    "# df = df.drop('image_path', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b931591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "train_df['label'] = train_df['label'] - 1\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(f'feather-in-focus/train_images{img_path}' )\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img)\n",
    "#     return np.array(images)\n",
    "    return images\n",
    "\n",
    "# Load and preprocess images\n",
    "train_images = load_and_preprocess_images(train_df['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dda9ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "      <th>pre_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6078431372549019, 0.3843137254901961, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6588235294117647, 0.6235294117647059, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.8274509803921568, 0.796078431372549, 0.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6352941176470588, 0.6196078431372549, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.7098039215686275, 0.7137254901960784, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3568627450980392, 0.3568627450980392, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3411764705882353, 0.36470588235294116, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.043137254901960784, 0.13725490196078433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3137254901960784, 0.39215686274509803, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.21176470588235294, 0.30196078431372547, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      0   \n",
       "1        /train_images/2.jpg      0   \n",
       "2        /train_images/3.jpg      0   \n",
       "3        /train_images/4.jpg      0   \n",
       "4        /train_images/5.jpg      0   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    199   \n",
       "3922  /train_images/3923.jpg    199   \n",
       "3923  /train_images/3924.jpg    199   \n",
       "3924  /train_images/3925.jpg    199   \n",
       "3925  /train_images/3926.jpg    199   \n",
       "\n",
       "                                             attributes  \\\n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "...                                                 ...   \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "\n",
       "                                              pre_image  \n",
       "0     [[[0.6078431372549019, 0.3843137254901961, 0.1...  \n",
       "1     [[[0.6588235294117647, 0.6235294117647059, 0.5...  \n",
       "2     [[[0.8274509803921568, 0.796078431372549, 0.79...  \n",
       "3     [[[0.6352941176470588, 0.6196078431372549, 0.6...  \n",
       "4     [[[0.7098039215686275, 0.7137254901960784, 0.6...  \n",
       "...                                                 ...  \n",
       "3921  [[[0.3568627450980392, 0.3568627450980392, 0.3...  \n",
       "3922  [[[0.3411764705882353, 0.36470588235294116, 0....  \n",
       "3923  [[[0.043137254901960784, 0.13725490196078433, ...  \n",
       "3924  [[[0.3137254901960784, 0.39215686274509803, 0....  \n",
       "3925  [[[0.21176470588235294, 0.30196078431372547, 0...  \n",
       "\n",
       "[3926 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_image'] = train_images\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68c8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\meesa\\anaconda3\\envs\\feather-in-focus\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\meesa\\anaconda3\\envs\\feather-in-focus\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171317808/171317808 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the InceptionV3 model with pre-trained weights\n",
    "base_model = tf.keras.applications.ResNet101V2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    ")\n",
    "\n",
    "#For now, we will freeze the model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a Sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the base model (InceptionV3) to the Sequential model\n",
    "model.add(base_model)\n",
    "\n",
    "# Global Average Pooling layer\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\"))\n",
    "\n",
    "#More hidden layers, now with BatchNormalization\n",
    "model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "# Output Dense layer\n",
    "model.add(tf.keras.layers.Dense(200, activation=\"softmax\", name=\"output-layer\"))\n",
    "\n",
    "# As we allow the model to be trainable in some layers, it will be better to decrease the learning rate in this region\n",
    "# to avoid an exagerated change in the model weights \n",
    "\n",
    "base_learning_rate = 0.01 \n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "# Compile the model \n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea69ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet101v2 (Functional)    (None, 7, 7, 2048)        42626560  \n",
      "                                                                 \n",
      " global_average_pooling_lay  (None, 2048)              0         \n",
      " er (GlobalAveragePooling2D                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " output-layer (Dense)        (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43861448 (167.32 MB)\n",
      "Trainable params: 1233352 (4.70 MB)\n",
      "Non-trainable params: 42628096 (162.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b2fda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch shape: (64, 224, 224, 3) (64, 200)\n",
      "Validation batch shape: (64, 224, 224, 3) (64, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'df' is your DataFrame with columns 'image' and 'label'.\n",
    "# 'image' column contains the image arrays and 'label' column contains class labels.\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert 'image' column to numpy array\n",
    "train_images = np.stack(train_df['pre_image'].to_numpy())\n",
    "val_images = np.stack(val_df['pre_image'].to_numpy())\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels = tf.keras.utils.to_categorical(train_df['label'])\n",
    "val_labels = tf.keras.utils.to_categorical(val_df['label'])\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Example: Check the shape of the datasets\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Training batch shape:\", images.shape, labels.shape)\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    print(\"Validation batch shape:\", images.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef11ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "WARNING:tensorflow:From c:\\Users\\meesa\\anaconda3\\envs\\feather-in-focus\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\meesa\\anaconda3\\envs\\feather-in-focus\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "50/50 [==============================] - 109s 2s/step - loss: 4.1722 - accuracy: 0.1430 - val_loss: 8.3090 - val_accuracy: 0.1719\n",
      "Epoch 2/18\n",
      "50/50 [==============================] - 99s 2s/step - loss: 2.7740 - accuracy: 0.3111 - val_loss: 3.9280 - val_accuracy: 0.3125\n",
      "Epoch 3/18\n",
      "50/50 [==============================] - 111s 2s/step - loss: 2.2533 - accuracy: 0.4029 - val_loss: 3.3525 - val_accuracy: 0.3385\n",
      "Epoch 4/18\n",
      "50/50 [==============================] - 101s 2s/step - loss: 1.7835 - accuracy: 0.5045 - val_loss: 3.0220 - val_accuracy: 0.3854\n",
      "Epoch 5/18\n",
      "50/50 [==============================] - 107s 2s/step - loss: 1.5995 - accuracy: 0.5532 - val_loss: 3.0382 - val_accuracy: 0.3750\n",
      "Epoch 6/18\n",
      "50/50 [==============================] - 94s 2s/step - loss: 1.4097 - accuracy: 0.6057 - val_loss: 3.0968 - val_accuracy: 0.3750\n",
      "Epoch 7/18\n",
      "50/50 [==============================] - 93s 2s/step - loss: 1.2748 - accuracy: 0.6404 - val_loss: 3.0482 - val_accuracy: 0.4323\n",
      "Epoch 8/18\n",
      "50/50 [==============================] - 91s 2s/step - loss: 1.0942 - accuracy: 0.6828 - val_loss: 2.9588 - val_accuracy: 0.4010\n",
      "Epoch 9/18\n",
      "50/50 [==============================] - 94s 2s/step - loss: 1.0090 - accuracy: 0.6946 - val_loss: 2.9844 - val_accuracy: 0.4062\n",
      "Epoch 10/18\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.9712 - accuracy: 0.7121 - val_loss: 3.4492 - val_accuracy: 0.4479\n",
      "Epoch 11/18\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.8751 - accuracy: 0.7338 - val_loss: 3.2848 - val_accuracy: 0.3958\n",
      "Epoch 12/18\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.7669 - accuracy: 0.7516 - val_loss: 3.3535 - val_accuracy: 0.3958\n",
      "Epoch 13/18\n",
      "50/50 [==============================] - 96s 2s/step - loss: 0.7650 - accuracy: 0.7608 - val_loss: 3.4351 - val_accuracy: 0.3906\n",
      "Epoch 14/18\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.7638 - accuracy: 0.7774 - val_loss: 3.0227 - val_accuracy: 0.4375\n",
      "Epoch 15/18\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.9079 - accuracy: 0.7318 - val_loss: 3.1477 - val_accuracy: 0.4062\n",
      "Epoch 16/18\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.8021 - accuracy: 0.7561 - val_loss: 3.3840 - val_accuracy: 0.4062\n",
      "Epoch 17/18\n",
      "50/50 [==============================] - 94s 2s/step - loss: 0.6348 - accuracy: 0.8054 - val_loss: 3.4359 - val_accuracy: 0.4167\n",
      "Epoch 18/18\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.5532 - accuracy: 0.8309 - val_loss: 3.3319 - val_accuracy: 0.4219\n"
     ]
    }
   ],
   "source": [
    "#Setting the early_stop to avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=3,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=18,\n",
    "    steps_per_epoch=len(train_dataset),\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=int(0.25 * len(val_dataset)),\n",
    "#     callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe5059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  377\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f1930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 98s 2s/step - loss: 0.3907 - accuracy: 0.8732 - val_loss: 3.0532 - val_accuracy: 0.4115\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.3761 - accuracy: 0.8831 - val_loss: 2.9454 - val_accuracy: 0.4115\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.3414 - accuracy: 0.8927 - val_loss: 2.8851 - val_accuracy: 0.4167\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 92s 2s/step - loss: 0.3161 - accuracy: 0.8990 - val_loss: 2.8530 - val_accuracy: 0.4115\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.3174 - accuracy: 0.9029 - val_loss: 2.8289 - val_accuracy: 0.4115\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.3064 - accuracy: 0.8990 - val_loss: 2.8212 - val_accuracy: 0.4219\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 91s 2s/step - loss: 0.3128 - accuracy: 0.8968 - val_loss: 2.8078 - val_accuracy: 0.4375\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.2934 - accuracy: 0.9089 - val_loss: 2.7991 - val_accuracy: 0.4375\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.3061 - accuracy: 0.9025 - val_loss: 2.7991 - val_accuracy: 0.4427\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 99s 2s/step - loss: 0.2906 - accuracy: 0.9105 - val_loss: 2.8028 - val_accuracy: 0.4375\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.2814 - accuracy: 0.9134 - val_loss: 2.7987 - val_accuracy: 0.4427\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 95s 2s/step - loss: 0.2835 - accuracy: 0.9143 - val_loss: 2.7917 - val_accuracy: 0.4427\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 93s 2s/step - loss: 0.2637 - accuracy: 0.9134 - val_loss: 2.7850 - val_accuracy: 0.4323\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 260\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    # Now that we will allow some layers to be unfreezed, it's better to decrease the learning rate to avoid dramatic changes in those \n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100)\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=4,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "\n",
    "fine_tune_epochs = 12\n",
    "total_epochs =  18 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         steps_per_epoch=len(train_dataset),\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=int(0.25 * len(val_dataset)),\n",
    "                         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2234e20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meesa\\anaconda3\\envs\\feather-in-focus\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c06ec463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 109s 857ms/step\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_images2(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(f'feather-in-focus/test_images{img_path}')\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "test_df = pd.read_csv(\"feather-in-focus/test_images_path.csv\")\n",
    "test_images = load_and_preprocess_images2(test_df['image_path'])\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'label': predicted_labels+1\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
