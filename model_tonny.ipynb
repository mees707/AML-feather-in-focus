{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a20399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58164ab",
   "metadata": {},
   "source": [
    "# model trainen zonder attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211a1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label\n",
       "0        /train_images/1.jpg      1\n",
       "1        /train_images/2.jpg      1\n",
       "2        /train_images/3.jpg      1\n",
       "3        /train_images/4.jpg      1\n",
       "4        /train_images/5.jpg      1\n",
       "...                      ...    ...\n",
       "3921  /train_images/3922.jpg    200\n",
       "3922  /train_images/3923.jpg    200\n",
       "3923  /train_images/3924.jpg    200\n",
       "3924  /train_images/3925.jpg    200\n",
       "3925  /train_images/3926.jpg    200\n",
       "\n",
       "[3926 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"feather-in-focus/class_names.npy\", allow_pickle=True).item()\n",
    "df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db273c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = np.load(\"feather-in-focus/attributes.npy\")\n",
    "len(attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35500a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      1   \n",
       "1        /train_images/2.jpg      1   \n",
       "2        /train_images/3.jpg      1   \n",
       "3        /train_images/4.jpg      1   \n",
       "4        /train_images/5.jpg      1   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    200   \n",
       "3922  /train_images/3923.jpg    200   \n",
       "3923  /train_images/3924.jpg    200   \n",
       "3924  /train_images/3925.jpg    200   \n",
       "3925  /train_images/3926.jpg    200   \n",
       "\n",
       "                                             attributes  \n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "...                                                 ...  \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "\n",
       "[3926 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_list = []\n",
    "for i in range(len(df)):\n",
    "    att_list.append(attributes[df['label'][i]-1])  \n",
    "    \n",
    "df['attributes'] = att_list\n",
    "# df = df.drop('image_path', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b931591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "train_df['label'] = train_df['label'] - 1\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(f'feather-in-focus/train_images{img_path}' )\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img)\n",
    "#     return np.array(images)\n",
    "    return images\n",
    "\n",
    "# Load and preprocess images\n",
    "train_images = load_and_preprocess_images(train_df['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dda9ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "      <th>pre_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6078431372549019, 0.3843137254901961, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6588235294117647, 0.6235294117647059, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.8274509803921568, 0.796078431372549, 0.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6352941176470588, 0.6196078431372549, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.7098039215686275, 0.7137254901960784, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3568627450980392, 0.3568627450980392, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3411764705882353, 0.36470588235294116, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.043137254901960784, 0.13725490196078433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3137254901960784, 0.39215686274509803, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.21176470588235294, 0.30196078431372547, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      0   \n",
       "1        /train_images/2.jpg      0   \n",
       "2        /train_images/3.jpg      0   \n",
       "3        /train_images/4.jpg      0   \n",
       "4        /train_images/5.jpg      0   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    199   \n",
       "3922  /train_images/3923.jpg    199   \n",
       "3923  /train_images/3924.jpg    199   \n",
       "3924  /train_images/3925.jpg    199   \n",
       "3925  /train_images/3926.jpg    199   \n",
       "\n",
       "                                             attributes  \\\n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "...                                                 ...   \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "\n",
       "                                              pre_image  \n",
       "0     [[[0.6078431372549019, 0.3843137254901961, 0.1...  \n",
       "1     [[[0.6588235294117647, 0.6235294117647059, 0.5...  \n",
       "2     [[[0.8274509803921568, 0.796078431372549, 0.79...  \n",
       "3     [[[0.6352941176470588, 0.6196078431372549, 0.6...  \n",
       "4     [[[0.7098039215686275, 0.7137254901960784, 0.6...  \n",
       "...                                                 ...  \n",
       "3921  [[[0.3568627450980392, 0.3568627450980392, 0.3...  \n",
       "3922  [[[0.3411764705882353, 0.36470588235294116, 0....  \n",
       "3923  [[[0.043137254901960784, 0.13725490196078433, ...  \n",
       "3924  [[[0.3137254901960784, 0.39215686274509803, 0....  \n",
       "3925  [[[0.21176470588235294, 0.30196078431372547, 0...  \n",
       "\n",
       "[3926 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_image'] = train_images\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Flatten, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68c8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inception_v3_input (InputLayer  [(None, 224, 224, 3  0          []                               \n",
      " )                              )]                                                                \n",
      "                                                                                                  \n",
      " inception_v3 (Functional)      (None, 5, 5, 2048)   21802784    ['inception_v3_input[0][0]']     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 312)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 51200)        0           ['inception_v3[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          40064       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 51328)        0           ['flatten[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output-layer (Dense)           (None, 200)          10265800    ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,108,648\n",
      "Trainable params: 10,305,864\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a Sequential model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Flatten the output from InceptionV3\n",
    "flattened_output = Flatten()(model.output)\n",
    "\n",
    "# Assuming your attribute features have a shape of (312,)\n",
    "attribute_input = Input(shape=(312,))\n",
    "dense_attribute_output = Dense(128, activation='relu')(attribute_input)\n",
    "\n",
    "# Concatenate InceptionV3 output with attribute features\n",
    "concatenated_output = Concatenate()([flattened_output, dense_attribute_output])\n",
    "\n",
    "# Output Dense layer\n",
    "output_layer = Dense(200, activation=\"softmax\", name=\"output-layer\")(concatenated_output)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=[model.input, attribute_input], outputs=output_layer)\n",
    "\n",
    "# As we allow the model to be trainable in some layers,\n",
    "# it will be better to decrease the learning rate in this region\n",
    "# to avoid an exaggerated change in the model weights\n",
    "base_learning_rate = 0.01 \n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "epochs = 10  # You can adjust the number of epochs as needed\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0361ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "tmp = [attributes[i-1] for i in train_df['label']]\n",
    "train_df['attributes'] = tmp\n",
    "\n",
    "tmp = [attributes[i-1] for i in val_df['label']]\n",
    "val_df['attributes'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b2fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split your data into training and validation sets\n",
    "# train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Convert 'image' column to numpy array\n",
    "# train_images = np.stack(train_df['pre_image'].to_numpy())\n",
    "# val_images = np.stack(val_df['pre_image'].to_numpy())\n",
    "\n",
    "# # Convert labels to categorical\n",
    "# train_labels = tf.keras.utils.to_categorical(train_df['label'])\n",
    "# val_labels = tf.keras.utils.to_categorical(val_df['label'])\n",
    "\n",
    "# # Create datasets\n",
    "# batch_size = 64\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "# val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# # Example: Check the shape of the datasets\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     print(\"Training batch shape:\", images.shape, labels.shape)\n",
    "\n",
    "# for images, labels in val_dataset.take(1):\n",
    "#     print(\"Validation batch shape:\", images.shape, labels.shape)\n",
    "\n",
    "# Convert 'pre_image' column to numpy array\n",
    "train_images = np.stack(train_df['pre_image'])\n",
    "val_images = np.stack(val_df['pre_image'])\n",
    "\n",
    "# Convert 'attributes' column to numpy array\n",
    "train_attributes = np.stack(train_df['attributes'])\n",
    "val_attributes = np.stack(val_df['attributes'])\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels = tf.keras.utils.to_categorical(train_df['label'])\n",
    "val_labels = tf.keras.utils.to_categorical(val_df['label'])\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8726822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Include both image and attribute data in the training dataset\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(([train_images, train_attributes], train_labels))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
    "\n",
    "# # Include both image and attribute data in the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices(([val_images, val_attributes], val_labels))\n",
    "# val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 224, 224, 3) dtype=float64>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Setting the early_stop to avoid overfitting\u001b[39;00m\n\u001b[1;32m      2\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m      3\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      4\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      5\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[0;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;43;03m#     callbacks=[early_stop],\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/r1/x5mr_p9s73b4vnvnkz5dp8f00000gn/T/__autograph_generated_filetj0x6ly_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/tonny/opt/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 224, 224, 3) dtype=float64>]\n"
     ]
    }
   ],
   "source": [
    "# Setting the early_stop to avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=3,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_dataset),\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=int(0.25 * len(val_dataset)),\n",
    "    callbacks=[early_stop],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  311\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x00000291FC31F400>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxvt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\weakref.py\", line 371, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 150s 1s/step - loss: 1.3820 - accuracy: 0.6076 - val_loss: 2.5304 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 49s 983ms/step - loss: 1.3068 - accuracy: 0.6127 - val_loss: 2.4098 - val_accuracy: 0.4010\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 47s 942ms/step - loss: 1.2290 - accuracy: 0.6338 - val_loss: 2.3571 - val_accuracy: 0.4010\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 49s 976ms/step - loss: 1.1798 - accuracy: 0.6583 - val_loss: 2.3330 - val_accuracy: 0.4062\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 1.1659 - accuracy: 0.6697 - val_loss: 2.3108 - val_accuracy: 0.4010\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 48s 951ms/step - loss: 1.1533 - accuracy: 0.6640 - val_loss: 2.2982 - val_accuracy: 0.4167\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 47s 946ms/step - loss: 1.1234 - accuracy: 0.6758 - val_loss: 2.2888 - val_accuracy: 0.4219\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 1.0661 - accuracy: 0.6955 - val_loss: 2.2815 - val_accuracy: 0.4219\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 48s 952ms/step - loss: 1.0758 - accuracy: 0.6911 - val_loss: 2.2786 - val_accuracy: 0.4271\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 48s 956ms/step - loss: 1.0665 - accuracy: 0.6968 - val_loss: 2.2659 - val_accuracy: 0.4323\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 47s 939ms/step - loss: 1.0864 - accuracy: 0.6882 - val_loss: 2.2593 - val_accuracy: 0.4375\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 49s 975ms/step - loss: 1.0583 - accuracy: 0.6975 - val_loss: 2.2576 - val_accuracy: 0.4427\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 46s 929ms/step - loss: 1.0535 - accuracy: 0.7022 - val_loss: 2.2543 - val_accuracy: 0.4479\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 1.0095 - accuracy: 0.7064 - val_loss: 2.2522 - val_accuracy: 0.4427\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 50s 934ms/step - loss: 1.0016 - accuracy: 0.7185 - val_loss: 2.2506 - val_accuracy: 0.4427\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 0.9814 - accuracy: 0.7252 - val_loss: 2.2471 - val_accuracy: 0.4427\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 49s 975ms/step - loss: 1.0047 - accuracy: 0.7083 - val_loss: 2.2457 - val_accuracy: 0.4427\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 0.9836 - accuracy: 0.7197 - val_loss: 2.2462 - val_accuracy: 0.4427\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 47s 945ms/step - loss: 0.9767 - accuracy: 0.7188 - val_loss: 2.2505 - val_accuracy: 0.4375\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 0.9647 - accuracy: 0.7226 - val_loss: 2.2474 - val_accuracy: 0.4375\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 47s 934ms/step - loss: 0.9774 - accuracy: 0.7178 - val_loss: 2.2422 - val_accuracy: 0.4375\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 0.9590 - accuracy: 0.7223 - val_loss: 2.2366 - val_accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 260\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    # Now that we will allow some layers to be unfreezed, it's better to decrease the learning rate to avoid dramatic changes in those \n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100)\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=4,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "\n",
    "fine_tune_epochs = 5\n",
    "total_epochs =  5 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         steps_per_epoch=len(train_dataset),\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=int(0.25 * len(val_dataset)),\n",
    "                         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ec463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('path_to_save_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
