{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the values per image that belong to the given attributes for each class\n",
    "attributes = np.load(\"feather-in-focus/attributes.npy\")\n",
    "\n",
    "# names of each bird class\n",
    "labels = np.load(\"feather-in-focus/class_names.npy\", allow_pickle=True).item()\n",
    "\n",
    "# list of training data containing: image location, labels per image \n",
    "data = pd.read_csv(\"feather-in-focus/train_images.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      1   \n",
       "1        /train_images/2.jpg      1   \n",
       "2        /train_images/3.jpg      1   \n",
       "3        /train_images/4.jpg      1   \n",
       "4        /train_images/5.jpg      1   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    200   \n",
       "3922  /train_images/3923.jpg    200   \n",
       "3923  /train_images/3924.jpg    200   \n",
       "3924  /train_images/3925.jpg    200   \n",
       "3925  /train_images/3926.jpg    200   \n",
       "\n",
       "                                             attributes  \n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "...                                                 ...  \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "\n",
       "[3926 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"feather-in-focus/class_names.npy\", allow_pickle=True).item()\n",
    "df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "att_list = []\n",
    "for i in range(len(df)):\n",
    "    att_list.append(attributes[df['label'][i]-1])  \n",
    "    \n",
    "df['attributes'] = att_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "      <th>pre_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6078431372549019, 0.3843137254901961, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6588235294117647, 0.6235294117647059, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.8274509803921568, 0.796078431372549, 0.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6352941176470588, 0.6196078431372549, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.7098039215686275, 0.7137254901960784, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3568627450980392, 0.3568627450980392, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3411764705882353, 0.36470588235294116, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.043137254901960784, 0.13725490196078433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3137254901960784, 0.39215686274509803, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.21176470588235294, 0.30196078431372547, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      0   \n",
       "1        /train_images/2.jpg      0   \n",
       "2        /train_images/3.jpg      0   \n",
       "3        /train_images/4.jpg      0   \n",
       "4        /train_images/5.jpg      0   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    199   \n",
       "3922  /train_images/3923.jpg    199   \n",
       "3923  /train_images/3924.jpg    199   \n",
       "3924  /train_images/3925.jpg    199   \n",
       "3925  /train_images/3926.jpg    199   \n",
       "\n",
       "                                             attributes  \\\n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "...                                                 ...   \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "\n",
       "                                              pre_image  \n",
       "0     [[[0.6078431372549019, 0.3843137254901961, 0.1...  \n",
       "1     [[[0.6588235294117647, 0.6235294117647059, 0.5...  \n",
       "2     [[[0.8274509803921568, 0.796078431372549, 0.79...  \n",
       "3     [[[0.6352941176470588, 0.6196078431372549, 0.6...  \n",
       "4     [[[0.7098039215686275, 0.7137254901960784, 0.6...  \n",
       "...                                                 ...  \n",
       "3921  [[[0.3568627450980392, 0.3568627450980392, 0.3...  \n",
       "3922  [[[0.3411764705882353, 0.36470588235294116, 0....  \n",
       "3923  [[[0.043137254901960784, 0.13725490196078433, ...  \n",
       "3924  [[[0.3137254901960784, 0.39215686274509803, 0....  \n",
       "3925  [[[0.21176470588235294, 0.30196078431372547, 0...  \n",
       "\n",
       "[3926 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = data['label'] - 1\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(f'feather-in-focus/train_images{img_path}' )\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load and preprocess images\n",
    "train_images = load_and_preprocess_images(data['image_path'])\n",
    "\n",
    "df['pre_image'] = train_images\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Flatten, Dense, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inception_v3_input (InputLayer  [(None, 224, 224, 3  0          []                               \n",
      " )                              )]                                                                \n",
      "                                                                                                  \n",
      " inception_v3 (Functional)      (None, 5, 5, 2048)   21802784    ['inception_v3_input[0][0]']     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 312)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 51200)        0           ['inception_v3[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          40064       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 51328)        0           ['flatten[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output-layer (Dense)           (None, 200)          10265800    ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,108,648\n",
      "Trainable params: 10,305,864\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded your data and attributes as train_df and attributes, respectively\n",
    "\n",
    "# Load the InceptionV3 model with pre-trained weights\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a Sequential model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Flatten the output from InceptionV3\n",
    "flattened_output = Flatten()(model.output)\n",
    "\n",
    "# Assuming your attribute features have a shape of (312,)\n",
    "attribute_input = Input(shape=(312,))\n",
    "dense_attribute_output = Dense(128, activation='relu')(attribute_input)\n",
    "\n",
    "# Concatenate InceptionV3 output with attribute features\n",
    "concatenated_output = Concatenate()([flattened_output, dense_attribute_output])\n",
    "\n",
    "# Output Dense layer\n",
    "output_layer = Dense(200, activation=\"softmax\", name=\"output-layer\")(concatenated_output)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=[model.input, attribute_input], outputs=output_layer)\n",
    "\n",
    "# As we allow the model to be trainable in some layers,\n",
    "# it will be better to decrease the learning rate in this region\n",
    "# to avoid an exaggerated change in the model weights\n",
    "base_learning_rate = 0.01 \n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "epochs = 10  # You can adjust the number of epochs as needed\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[1;32m     17\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m---> 19\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attributes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_images))\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[1;32m     22\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(([val_images, val_attributes], val_labels))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:809\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    733\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4551\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4550\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4551\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4552\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m   4553\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:125\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    124\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 125\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1631\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1632\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1633\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1640\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1643\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "# Split your data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert 'pre_image' column to numpy array\n",
    "train_images = np.stack(train_df['pre_image'].to_numpy())\n",
    "val_images = np.stack(val_df['pre_image'].to_numpy())\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels = tf.keras.utils.to_categorical(train_df['label'])\n",
    "val_labels = tf.keras.utils.to_categorical(val_df['label'])\n",
    "\n",
    "# Convert 'attributes' column to numpy array\n",
    "train_attributes = np.stack(train_df['attributes'].to_numpy())\n",
    "val_attributes = np.stack(val_df['attributes'].to_numpy())\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(([train_images, train_attributes], train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(([val_images, val_attributes], val_labels))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inception_v3_input (InputLayer  [(None, 224, 224, 3  0          []                               \n",
      " )                              )]                                                                \n",
      "                                                                                                  \n",
      " inception_v3 (Functional)      (None, 5, 5, 2048)   21802784    ['inception_v3_input[0][0]']     \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 312)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 51200)        0           ['inception_v3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          40064       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 51328)        0           ['flatten_2[0][0]',              \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " output-layer (Dense)           (None, 200)          10265800    ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,108,648\n",
      "Trainable params: 10,305,864\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch shape: (16, 224, 224, 3) (16, 198)\n",
      "Validation batch shape: (16, 224, 224, 3) (16, 198)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert 'image' column to numpy array\n",
    "train_images = np.stack(train_df['pre_image'].to_numpy())\n",
    "val_images = np.stack(val_df['pre_image'].to_numpy())\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels = tf.keras.utils.to_categorical(train_df['label'])\n",
    "val_labels = tf.keras.utils.to_categorical(val_df['label'])\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Example: Check the shape of the datasets\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Training batch shape:\", images.shape, labels.shape)\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    print(\"Validation batch shape:\", images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using dataset as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Setting the early_stop to avoid overfitting\u001b[39;00m\n\u001b[1;32m      2\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m      3\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      4\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      5\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[0;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:747\u001b[0m, in \u001b[0;36mDatasetAdapter._validate_args\u001b[0;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Arguments that shouldn't be passed.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_none_or_empty(y):\n\u001b[0;32m--> 747\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`y` argument is not supported when using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    748\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_none_or_empty(sample_weights):\n\u001b[1;32m    750\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_weight` argument is not supported when using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using dataset as input."
     ]
    }
   ],
   "source": [
    "#Setting the early_stop to avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=3,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    attributes,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_dataset),\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=int(0.25 * len(val_dataset)),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
