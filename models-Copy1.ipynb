{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a20399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58164ab",
   "metadata": {},
   "source": [
    "# model trainen zonder attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211a1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label\n",
       "0        /train_images/1.jpg      1\n",
       "1        /train_images/2.jpg      1\n",
       "2        /train_images/3.jpg      1\n",
       "3        /train_images/4.jpg      1\n",
       "4        /train_images/5.jpg      1\n",
       "...                      ...    ...\n",
       "3921  /train_images/3922.jpg    200\n",
       "3922  /train_images/3923.jpg    200\n",
       "3923  /train_images/3924.jpg    200\n",
       "3924  /train_images/3925.jpg    200\n",
       "3925  /train_images/3926.jpg    200\n",
       "\n",
       "[3926 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load(\"feather-in-focus/class_names.npy\", allow_pickle=True).item()\n",
    "df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db273c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = np.load(\"feather-in-focus/attributes.npy\")\n",
    "len(attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35500a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>200</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label  \\\n",
       "0        /train_images/1.jpg      1   \n",
       "1        /train_images/2.jpg      1   \n",
       "2        /train_images/3.jpg      1   \n",
       "3        /train_images/4.jpg      1   \n",
       "4        /train_images/5.jpg      1   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    200   \n",
       "3922  /train_images/3923.jpg    200   \n",
       "3923  /train_images/3924.jpg    200   \n",
       "3924  /train_images/3925.jpg    200   \n",
       "3925  /train_images/3926.jpg    200   \n",
       "\n",
       "                                             attributes  \n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...  \n",
       "...                                                 ...  \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...  \n",
       "\n",
       "[3926 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_list = []\n",
    "for i in range(len(df)):\n",
    "    att_list.append(attributes[df['label'][i]-1])  \n",
    "    \n",
    "df['attributes'] = att_list\n",
    "# df = df.drop('image_path', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b931591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv(\"feather-in-focus/train_images.csv\")\n",
    "train_df['label'] = train_df['label'] - 1\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(f'feather-in-focus/train_images{img_path}' )\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img)\n",
    "#     return np.array(images)\n",
    "    return images\n",
    "\n",
    "# Load and preprocess images\n",
    "train_images = load_and_preprocess_images(train_df['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda9ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>attributes</th>\n",
       "      <th>pre_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/train_images/1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6078431372549019, 0.3843137254901961, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/train_images/2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6588235294117647, 0.6235294117647059, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/train_images/3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.8274509803921568, 0.796078431372549, 0.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/train_images/4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.6352941176470588, 0.6196078431372549, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/train_images/5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010638400403539122, 0.010638400403539122, 0...</td>\n",
       "      <td>[[[0.7098039215686275, 0.7137254901960784, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>/train_images/3922.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3568627450980392, 0.3568627450980392, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>/train_images/3923.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3411764705882353, 0.36470588235294116, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>/train_images/3924.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.043137254901960784, 0.13725490196078433, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>/train_images/3925.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.3137254901960784, 0.39215686274509803, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>/train_images/3926.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>[0.04378018711713792, 0.02814440600394273, 0.0...</td>\n",
       "      <td>[[[0.21176470588235294, 0.30196078431372547, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image_path  label   \n",
       "0        /train_images/1.jpg      0  \\\n",
       "1        /train_images/2.jpg      0   \n",
       "2        /train_images/3.jpg      0   \n",
       "3        /train_images/4.jpg      0   \n",
       "4        /train_images/5.jpg      0   \n",
       "...                      ...    ...   \n",
       "3921  /train_images/3922.jpg    199   \n",
       "3922  /train_images/3923.jpg    199   \n",
       "3923  /train_images/3924.jpg    199   \n",
       "3924  /train_images/3925.jpg    199   \n",
       "3925  /train_images/3926.jpg    199   \n",
       "\n",
       "                                             attributes   \n",
       "0     [0.010638400403539122, 0.010638400403539122, 0...  \\\n",
       "1     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "2     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "3     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "4     [0.010638400403539122, 0.010638400403539122, 0...   \n",
       "...                                                 ...   \n",
       "3921  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3922  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3923  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3924  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "3925  [0.04378018711713792, 0.02814440600394273, 0.0...   \n",
       "\n",
       "                                              pre_image  \n",
       "0     [[[0.6078431372549019, 0.3843137254901961, 0.1...  \n",
       "1     [[[0.6588235294117647, 0.6235294117647059, 0.5...  \n",
       "2     [[[0.8274509803921568, 0.796078431372549, 0.79...  \n",
       "3     [[[0.6352941176470588, 0.6196078431372549, 0.6...  \n",
       "4     [[[0.7098039215686275, 0.7137254901960784, 0.6...  \n",
       "...                                                 ...  \n",
       "3921  [[[0.3568627450980392, 0.3568627450980392, 0.3...  \n",
       "3922  [[[0.3411764705882353, 0.36470588235294116, 0....  \n",
       "3923  [[[0.043137254901960784, 0.13725490196078433, ...  \n",
       "3924  [[[0.3137254901960784, 0.39215686274509803, 0....  \n",
       "3925  [[[0.21176470588235294, 0.30196078431372547, 0...  \n",
       "\n",
       "[3926 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_image'] = train_images\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68c8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the InceptionV3 model with pre-trained weights\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "#For now, we will freeze the model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a Sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the base model (InceptionV3) to the Sequential model\n",
    "model.add(base_model)\n",
    "\n",
    "# Global Average Pooling layer\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\"))\n",
    "\n",
    "#More hidden layers, now with BatchNormalization\n",
    "model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "# Output Dense layer\n",
    "model.add(tf.keras.layers.Dense(200, activation=\"softmax\", name=\"output-layer\"))\n",
    "\n",
    "# As we allow the model to be trainable in some layers, it will be better to decrease the learning rate in this region\n",
    "# to avoid an exagerated change in the model weights \n",
    "\n",
    "base_learning_rate = 0.01 \n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "\n",
    "# Compile the model \n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea69ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling_laye  (None, 2048)             0         \n",
      " r (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " output-layer (Dense)        (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,037,672\n",
      "Trainable params: 1,233,352\n",
      "Non-trainable params: 21,804,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2fda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch shape: (64, 224, 224, 3) (64, 200)\n",
      "Validation batch shape: (64, 224, 224, 3) (64, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'df' is your DataFrame with columns 'image' and 'label'.\n",
    "# 'image' column contains the image arrays and 'label' column contains class labels.\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert 'image' column to numpy array\n",
    "train_images = np.stack(train_df['pre_image'].to_numpy())\n",
    "val_images = np.stack(val_df['pre_image'].to_numpy())\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels = tf.keras.utils.to_categorical(train_df['label'])\n",
    "val_labels = tf.keras.utils.to_categorical(val_df['label'])\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Example: Check the shape of the datasets\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Training batch shape:\", images.shape, labels.shape)\n",
    "\n",
    "for images, labels in val_dataset.take(1):\n",
    "    print(\"Validation batch shape:\", images.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "43/43 [==============================] - 50s 1s/step - loss: 4.5483 - accuracy: 0.0921 - val_loss: 22.6118 - val_accuracy: 0.0391\n",
      "Epoch 2/18\n",
      "43/43 [==============================] - 44s 1s/step - loss: 3.2038 - accuracy: 0.2405 - val_loss: 6.1927 - val_accuracy: 0.1797\n",
      "Epoch 3/18\n",
      "43/43 [==============================] - 42s 989ms/step - loss: 2.6069 - accuracy: 0.3359 - val_loss: 4.3931 - val_accuracy: 0.2344\n",
      "Epoch 4/18\n",
      "43/43 [==============================] - 42s 986ms/step - loss: 2.0939 - accuracy: 0.4316 - val_loss: 3.8064 - val_accuracy: 0.2695\n",
      "Epoch 5/18\n",
      "43/43 [==============================] - 42s 968ms/step - loss: 1.8126 - accuracy: 0.4836 - val_loss: 3.8836 - val_accuracy: 0.2656\n",
      "Epoch 6/18\n",
      "43/43 [==============================] - 42s 969ms/step - loss: 1.5990 - accuracy: 0.5360 - val_loss: 3.7777 - val_accuracy: 0.3203\n",
      "Epoch 7/18\n",
      "43/43 [==============================] - 43s 998ms/step - loss: 1.3821 - accuracy: 0.6052 - val_loss: 3.8014 - val_accuracy: 0.2852\n",
      "Epoch 8/18\n",
      "43/43 [==============================] - 42s 980ms/step - loss: 1.1987 - accuracy: 0.6383 - val_loss: 3.8398 - val_accuracy: 0.2812\n",
      "Epoch 9/18\n",
      "43/43 [==============================] - 42s 973ms/step - loss: 1.1180 - accuracy: 0.6547 - val_loss: 3.9025 - val_accuracy: 0.3164\n",
      "Epoch 10/18\n",
      "43/43 [==============================] - 42s 972ms/step - loss: 0.9866 - accuracy: 0.7071 - val_loss: 3.9737 - val_accuracy: 0.3047\n",
      "Epoch 11/18\n",
      "43/43 [==============================] - 42s 977ms/step - loss: 0.8961 - accuracy: 0.7209 - val_loss: 4.6221 - val_accuracy: 0.2695\n",
      "Epoch 12/18\n",
      "43/43 [==============================] - 42s 976ms/step - loss: 0.8124 - accuracy: 0.7493 - val_loss: 4.6128 - val_accuracy: 0.3164\n",
      "Epoch 13/18\n",
      "43/43 [==============================] - 42s 976ms/step - loss: 0.7759 - accuracy: 0.7613 - val_loss: 4.7990 - val_accuracy: 0.2617\n",
      "Epoch 14/18\n",
      "43/43 [==============================] - 42s 973ms/step - loss: 0.6518 - accuracy: 0.7944 - val_loss: 4.7377 - val_accuracy: 0.3164\n",
      "Epoch 15/18\n",
      "43/43 [==============================] - 42s 975ms/step - loss: 0.5877 - accuracy: 0.8202 - val_loss: 4.0795 - val_accuracy: 0.3281\n",
      "Epoch 16/18\n",
      "43/43 [==============================] - 42s 976ms/step - loss: 0.5526 - accuracy: 0.8180 - val_loss: 4.3666 - val_accuracy: 0.3086\n",
      "Epoch 17/18\n",
      "43/43 [==============================] - 42s 969ms/step - loss: 0.5783 - accuracy: 0.8195 - val_loss: 4.3067 - val_accuracy: 0.3516\n",
      "Epoch 18/18\n",
      "43/43 [==============================] - 41s 965ms/step - loss: 0.5587 - accuracy: 0.8250 - val_loss: 4.6251 - val_accuracy: 0.3320\n"
     ]
    }
   ],
   "source": [
    "#Setting the early_stop to avoid overfitting\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=3,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=18,\n",
    "    steps_per_epoch=len(train_dataset),\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=int(0.25 * len(val_dataset)),\n",
    "#     callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  311\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x00000291FC31F400>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxvt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\weakref.py\", line 371, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 150s 1s/step - loss: 1.3820 - accuracy: 0.6076 - val_loss: 2.5304 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 49s 983ms/step - loss: 1.3068 - accuracy: 0.6127 - val_loss: 2.4098 - val_accuracy: 0.4010\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 47s 942ms/step - loss: 1.2290 - accuracy: 0.6338 - val_loss: 2.3571 - val_accuracy: 0.4010\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 49s 976ms/step - loss: 1.1798 - accuracy: 0.6583 - val_loss: 2.3330 - val_accuracy: 0.4062\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 1.1659 - accuracy: 0.6697 - val_loss: 2.3108 - val_accuracy: 0.4010\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 48s 951ms/step - loss: 1.1533 - accuracy: 0.6640 - val_loss: 2.2982 - val_accuracy: 0.4167\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 47s 946ms/step - loss: 1.1234 - accuracy: 0.6758 - val_loss: 2.2888 - val_accuracy: 0.4219\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 1.0661 - accuracy: 0.6955 - val_loss: 2.2815 - val_accuracy: 0.4219\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 48s 952ms/step - loss: 1.0758 - accuracy: 0.6911 - val_loss: 2.2786 - val_accuracy: 0.4271\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 48s 956ms/step - loss: 1.0665 - accuracy: 0.6968 - val_loss: 2.2659 - val_accuracy: 0.4323\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 47s 939ms/step - loss: 1.0864 - accuracy: 0.6882 - val_loss: 2.2593 - val_accuracy: 0.4375\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 49s 975ms/step - loss: 1.0583 - accuracy: 0.6975 - val_loss: 2.2576 - val_accuracy: 0.4427\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 46s 929ms/step - loss: 1.0535 - accuracy: 0.7022 - val_loss: 2.2543 - val_accuracy: 0.4479\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 1.0095 - accuracy: 0.7064 - val_loss: 2.2522 - val_accuracy: 0.4427\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 50s 934ms/step - loss: 1.0016 - accuracy: 0.7185 - val_loss: 2.2506 - val_accuracy: 0.4427\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 0.9814 - accuracy: 0.7252 - val_loss: 2.2471 - val_accuracy: 0.4427\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 49s 975ms/step - loss: 1.0047 - accuracy: 0.7083 - val_loss: 2.2457 - val_accuracy: 0.4427\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 0.9836 - accuracy: 0.7197 - val_loss: 2.2462 - val_accuracy: 0.4427\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 47s 945ms/step - loss: 0.9767 - accuracy: 0.7188 - val_loss: 2.2505 - val_accuracy: 0.4375\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 47s 948ms/step - loss: 0.9647 - accuracy: 0.7226 - val_loss: 2.2474 - val_accuracy: 0.4375\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 47s 934ms/step - loss: 0.9774 - accuracy: 0.7178 - val_loss: 2.2422 - val_accuracy: 0.4375\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 0.9590 - accuracy: 0.7223 - val_loss: 2.2366 - val_accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 260\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "    # Now that we will allow some layers to be unfreezed, it's better to decrease the learning rate to avoid dramatic changes in those \n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=base_learning_rate/100)\n",
    "\n",
    "# Compile the model again\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=4,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "\n",
    "fine_tune_epochs = 12\n",
    "total_epochs =  18 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         steps_per_epoch=len(train_dataset),\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=int(0.25 * len(val_dataset)),\n",
    "                         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ec463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('path_to_save_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
